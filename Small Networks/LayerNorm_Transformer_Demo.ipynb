{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8a44e5-afec-4a83-974e-30f45d9f9051",
   "metadata": {},
   "source": [
    "# Layer Normalization (LayerNorm)\n",
    "\n",
    "**What is LayerNorm?**  \n",
    "Layer Normalization is a technique to stabilize and accelerate training by normalizing\n",
    "the inputs across the **features** of each sample (not across the batch like BatchNorm).\n",
    "It is especially important in **Transformers**, where it is used after attention\n",
    "and feed-forward blocks.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ How it works\n",
    "For an input vector $ x \\in \\mathbb{R}^d $:\n",
    "\n",
    "1. Compute the mean:\n",
    "$$\n",
    "\\mu = \\frac{1}{d} \\sum_{i=1}^{d} x_i\n",
    "$$\n",
    "\n",
    "2. Compute the variance:\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{d} \\sum_{i=1}^{d} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "3. Normalize:\n",
    "$$\n",
    "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "4. Scale and shift with learnable parameters:\n",
    "$$\n",
    "y_i = \\gamma \\hat{x}_i + \\beta\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Key Properties\n",
    "- Works **independently per sample** â†’ does not depend on batch size.  \n",
    "- Normalizes across **features (d)**, not across the batch.  \n",
    "- Always used in **Transformer layers** to stabilize training.  \n",
    "- Parameters:  \n",
    "  - $ \\gamma $: learnable scale  \n",
    "  - $ \\beta $: learnable bias  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Why Transformers use LayerNorm\n",
    "- Handles variable sequence lengths and small batch sizes (where BatchNorm fails).  \n",
    "- Keeps activations stable, allowing very deep architectures to train.  \n",
    "- Essential for attention-based models (BERT, GPT, etc.).  \n",
    "\n",
    "---\n",
    "âœ… In practice: Every Transformer block applies LayerNorm around self-attention and feed-forward layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c92f7-9954-4be2-8005-139cd5e64bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c54b1c2b-1af9-4abb-bd98-432b223d9d01",
   "metadata": {},
   "source": [
    "# ðŸ§¾ BatchNorm vs LayerNorm: Why Each Fits Different Models\n",
    "\n",
    "## ðŸ”¹ Why BatchNorm is better in CNNs\n",
    "- **Spatial consistency across batch helps**: In images, each channel has similar statistics across a batch.  \n",
    "  BatchNorm leverages this by normalizing per channel across the batch and pixels.  \n",
    "- **Acts as regularization**: Randomness in batch statistics acts like noise injection â†’ improves generalization.  \n",
    "- **Efficiency**: Very efficient to compute in CNNs since it operates channel-wise over the batch.  \n",
    "- **If we use LayerNorm in CNNs**: We lose the batch-level regularization effect and often see slower or worse convergence.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Why LayerNorm is better in Transformers\n",
    "- **Batch statistics donâ€™t fit sequences**: In NLP/Transformers, inputs have variable sequence lengths and padding.  \n",
    "  BatchNorm would give unstable or misleading statistics.  \n",
    "- **Small/variable batch sizes**: Transformers often train with small or inconsistent batch sizes (long sequences).  \n",
    "  BatchNorm becomes unstable, but LayerNorm works even with `batch_size = 1`.  \n",
    "- **Stability in deep models**: Transformers can be *hundreds of layers deep*.  \n",
    "  LayerNorm guarantees stable per-token activations â†’ avoids exploding/vanishing signals.  \n",
    "- **Autoregressive inference**: GPT-style models often decode **one token at a time**.  \n",
    "  BatchNorm breaks in this case, but LayerNorm still works.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "- **BatchNorm** â†’ Great for **CNNs** (images), where batch statistics are meaningful and helpful.  \n",
    "- **LayerNorm** â†’ Essential for **Transformers / RNNs** (sequences), where batch statistics are unstable or undefined.  \n",
    "\n",
    "ðŸ‘‰ Thatâ€™s why:  \n",
    "- Vision models (ResNet, VGG, etc.) rely on **BatchNorm**.  \n",
    "- Transformer models (BERT, GPT, T5, etc.) rely on **LayerNorm**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26229095-726e-4a52-8d12-c4a9290af4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a7dd1-8ffd-4dc3-bff9-df5b8de239e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e223317-8b33-4abc-a29d-4ed3230069c3",
   "metadata": {},
   "source": [
    "## ðŸ§ª Using `nn.LayerNorm` like a Transformer\n",
    "\n",
    "Transformers normalize **each tokenâ€™s hidden vector** (dimension \\(D\\)) in tensors of shape `(N, T, D)`\n",
    "- `N`: batch size\n",
    "- `T`: sequence length (tokens/time)\n",
    "- `D`: model width (hidden size)\n",
    "\n",
    "We therefore set `normalized_shape=D` so PyTorch normalizes across the **last dimension** only.\n",
    "Below: a demo with dummy data; we show pre-LN (common in modern Transformers) around a residual block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe91e74e-59d3-403e-99cb-d04b27a02aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: torch.Size([2, 5, 16])\n",
      "ln.weight.shape: torch.Size([16])\n",
      "grad on ln.weight (first 5): tensor([-0.0033, -0.0077,  0.0009,  0.0047,  0.0165])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "N, T, D = 2, 5, 16         # batch, sequence length, hidden dim\n",
    "hidden = torch.randn(N, T, D)\n",
    "\n",
    "ln = nn.LayerNorm(D, eps=1e-5)  # normalize per token vector of size D\n",
    "ff = nn.Sequential(\n",
    "    nn.Linear(D, 4*D),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(4*D, D),\n",
    ")\n",
    "\n",
    "# Pre-LN Transformer-style block: Ln -> SubLayer -> Residual\n",
    "def transformer_block(x):\n",
    "    # LayerNorm per token\n",
    "    h = ln(x)\n",
    "    # Feed-forward sublayer\n",
    "    h = ff(h)\n",
    "    # Residual connection\n",
    "    return x + h\n",
    "\n",
    "out = transformer_block(hidden)\n",
    "loss = out.pow(2).mean()\n",
    "loss.backward()\n",
    "\n",
    "print(\"out shape:\", out.shape)\n",
    "print(\"ln.weight.shape:\", ln.weight.shape)\n",
    "print(\"grad on ln.weight (first 5):\", ln.weight.grad[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b1881-0df4-45fd-aa55-fa8f222a8619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025e51c6-2cd0-492b-9b9e-ef3043d0c200",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Tiny Transformer Block Demo with LayerNorm\n",
    "\n",
    "This example shows how to implement a **minimal Transformer encoder block** in PyTorch using:\n",
    "\n",
    "- **`nn.MultiheadAttention`** for self-attention  \n",
    "- **Residual connections** around attention and feed-forward layers  \n",
    "- **`nn.LayerNorm`** (Pre-LN style) for stability  \n",
    "- **A simple classifier head** on top of the Transformer block  \n",
    "\n",
    "The input is shaped `(N, T, D)`:\n",
    "- `N`: batch size  \n",
    "- `T`: sequence length (number of tokens)  \n",
    "- `D`: embedding dimension  \n",
    "\n",
    "We train it on dummy data to demonstrate:\n",
    "1. Forward and backward passes work.\n",
    "2. LayerNorm is applied correctly.\n",
    "3. The model can output logits for classification.\n",
    "\n",
    "This mirrors the structure of real Transformers (e.g., BERT, GPT) but in a **tiny, easy-to-read version**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca63e2c-5dd0-4279-ace9-ca30bf15aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fb987a-6538-4474-936a-1d196b1c40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallTransformerClassifier(\n",
      "  (block): SmallTransformerBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (ff): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (head): Linear(in_features=32, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "[TRAIN] logits shape: torch.Size([8, 5]), loss: 1.6507\n",
      "[EVAL ] logits shape: torch.Size([8, 5])\n",
      "\n",
      "LayerNorm weight shape: torch.Size([32])\n",
      "LayerNorm bias   shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Transformer Block with LayerNorm â€” full working demo\n",
    "\n",
    "# Define a tiny Transformer block\n",
    "class SmallTransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=32, nhead=4, dim_ff=64):\n",
    "        super().__init__()\n",
    "        # Multi-head self-attention\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n",
    "        # Feed-forward block\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim_ff, d_model),\n",
    "        )\n",
    "        # Two LayerNorms (pre-norm style)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Self-attention with residual\n",
    "        h = self.ln1(x)\n",
    "        attn_out, _ = self.attn(h, h, h)\n",
    "        x = x + attn_out\n",
    "\n",
    "        # Feed-forward with residual\n",
    "        h = self.ln2(x)\n",
    "        ff_out = self.ff(h)\n",
    "        x = x + ff_out\n",
    "        return x\n",
    "\n",
    "# Create dummy token batch\n",
    "torch.manual_seed(0)\n",
    "N, T, D = 8, 10, 32  # batch size, sequence length, hidden dim\n",
    "X = torch.randn(N, T, D)\n",
    "y = torch.randint(0, 5, (N,))  # dummy labels for 5 classes\n",
    "\n",
    "# Wrap block into a simple classifier\n",
    "class SmallTransformerClassifier(nn.Module):\n",
    "    def __init__(self, d_model=32, nhead=4, dim_ff=64, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.block = SmallTransformerBlock(d_model, nhead, dim_ff)\n",
    "        self.head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        # Take mean over sequence dimension as pooling\n",
    "        x = x.mean(dim=1)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "# Instantiate model, loss, optimizer\n",
    "model = SmallTransformerClassifier(d_model=D, nhead=4, dim_ff=64, num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# TRAINING mode\n",
    "model.train()\n",
    "logits_train = model(X)\n",
    "loss = criterion(logits_train, y)\n",
    "opt.zero_grad()\n",
    "loss.backward()\n",
    "opt.step()\n",
    "print(f\"\\n[TRAIN] logits shape: {logits_train.shape}, loss: {loss.item():.4f}\")\n",
    "\n",
    "# EVAL/INFERENCE mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_eval = model(X)\n",
    "print(f\"[EVAL ] logits shape: {logits_eval.shape}\")\n",
    "\n",
    "# check a LayerNormâ€™s params\n",
    "ln1 = model.block.ln1\n",
    "print(f\"\\nLayerNorm weight shape: {ln1.weight.shape}\")\n",
    "print(f\"LayerNorm bias   shape: {ln1.bias.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d2522-87da-4b2b-9c8f-9ed83cc4a3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83c9dd-6fe7-424f-a7ae-5c05801ca437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df819983-91e7-477b-9163-47bf883c0cad",
   "metadata": {},
   "source": [
    "## ðŸ”§ From-Scratch LayerNorm: forward + manual backward\n",
    "\n",
    "We normalize **per sample across features** (last dimension).  \n",
    "Given $x\\in\\mathbb{R}^{\\dots \\times D}$:\n",
    "\n",
    "- $\\mu=\\text{mean}(x,\\text{dim}=-1)$,\n",
    "- $\\sigma^2=\\text{mean}\\big((x-\\mu)^2,\\text{dim}=-1\\big)$,\n",
    "- $\\hat{x}=(x-\\mu)/\\sqrt{\\sigma^2+\\varepsilon}$,\n",
    "- $y=\\gamma\\hat{x}+\\beta$.\n",
    "\n",
    "**Backward (per sample, across features \\(D\\))**  \n",
    "Let $g=\\frac{\\partial \\mathcal{L}}{\\partial y}$ and $m=D$.  \n",
    "Then\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\beta} &= \\sum g, \\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\gamma} &= \\sum (g\\odot \\hat{x}), \\\\\n",
    "\\text{with } q &= g \\odot \\gamma, \\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial x}\n",
    "&= \\frac{1}{m}\\cdot\\frac{1}{\\sqrt{\\sigma^2+\\varepsilon}}\\Big(\n",
    "m\\,q \\;-\\; \\sum q \\;-\\; \\hat{x}\\,\\sum (q\\odot \\hat{x})\n",
    "\\Big),\n",
    "\\end{aligned}\n",
    "$$\n",
    "where the sums are over the **feature** axis (keep dimensions for broadcasting).\n",
    "\n",
    "Below is a minimal, transparent implementation plus a small gradient check against PyTorch autograd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cff629-b6e7-43ab-968b-231d457430d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormScratch:\n",
    "    \"\"\"LayerNorm over the last dimension only (â€¦ , D).\"\"\"\n",
    "    def __init__(self, D, eps=1e-5, device=\"cpu\", dtype=torch.float32):\n",
    "        self.D = D\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(D, device=device, dtype=dtype)\n",
    "        self.beta  = torch.zeros(D, device=device, dtype=dtype)\n",
    "        self.dgamma = torch.zeros_like(self.gamma)\n",
    "        self.dbeta  = torch.zeros_like(self.beta)\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu  = x.mean(dim=-1, keepdim=True)\n",
    "        var = ((x - mu) ** 2).mean(dim=-1, keepdim=True)\n",
    "        std = torch.sqrt(var + self.eps)\n",
    "        xhat = (x - mu) / std\n",
    "        y = xhat * self.gamma + self.beta\n",
    "        self.cache = (xhat, std, x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, dout):\n",
    "        xhat, std, x = self.cache\n",
    "        m = x.shape[-1]                       # number of features\n",
    "        # param grads (sum over all non-feature dims)\n",
    "        lead_axes = tuple(range(dout.dim()-1))\n",
    "        self.dgamma = (dout * xhat).sum(dim=lead_axes)\n",
    "        self.dbeta  = dout.sum(dim=lead_axes)\n",
    "        # input grad\n",
    "        q = dout * self.gamma\n",
    "        q_sum = q.sum(dim=-1, keepdim=True)\n",
    "        qxhat_sum = (q * xhat).sum(dim=-1, keepdim=True)\n",
    "        dx = (1.0 / m) * (1.0 / std) * (m * q - q_sum - xhat * qxhat_sum)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554e9cd5-52ab-461c-8d00-0bd95096d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2D] max |dx diff|   = 1.923558556882199e-08\n",
      "[2D] max |dgamma diff| = 0.0\n",
      "[2D] max |dbeta diff|  = 0.0\n",
      "[3D] max |dx diff|   = 5.024730853619985e-09\n",
      "[3D] max |dgamma diff| = 0.0\n",
      "[3D] max |dbeta diff|  = 0.0\n",
      "nn.LayerNorm out shape: torch.Size([2, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# 2D check\n",
    "N, D = 4, 6\n",
    "x = torch.randn(N, D, requires_grad=True)\n",
    "ln = LayerNormScratch(D)\n",
    "\n",
    "y = ln.forward(x)\n",
    "loss = (y**2).mean()\n",
    "dout = torch.autograd.grad(loss, y, create_graph=True)[0]\n",
    "dx_manual = ln.backward(dout)\n",
    "\n",
    "# autograd reference\n",
    "gamma = ln.gamma.detach().clone().requires_grad_(True)\n",
    "beta  = ln.beta.detach().clone().requires_grad_(True)\n",
    "mu = x.mean(dim=-1, keepdim=True)\n",
    "var = ((x - mu) ** 2).mean(dim=-1, keepdim=True)\n",
    "std = torch.sqrt(var + ln.eps)\n",
    "xhat = (x - mu) / std\n",
    "y_ref = xhat * gamma + beta\n",
    "loss_ref = (y_ref**2).mean()\n",
    "dx_auto, dgamma_auto, dbeta_auto = torch.autograd.grad(loss_ref, (x, gamma, beta))\n",
    "\n",
    "print(\"[2D] max |dx diff|   =\", (dx_manual - dx_auto).abs().max().item())\n",
    "print(\"[2D] max |dgamma diff| =\", (ln.dgamma - dgamma_auto).abs().max().item())\n",
    "print(\"[2D] max |dbeta diff|  =\", (ln.dbeta  - dbeta_auto ).abs().max().item())\n",
    "\n",
    "# 3D check\n",
    "N, T, D = 2, 5, 16\n",
    "x3 = torch.randn(N, T, D, requires_grad=True)\n",
    "ln3 = LayerNormScratch(D)\n",
    "\n",
    "y3 = ln3.forward(x3)\n",
    "loss3 = (y3**2).mean()\n",
    "dout3 = torch.autograd.grad(loss3, y3, create_graph=True)[0]\n",
    "dx3_manual = ln3.backward(dout3)\n",
    "\n",
    "gamma3 = ln3.gamma.detach().clone().requires_grad_(True)\n",
    "beta3  = ln3.beta.detach().clone().requires_grad_(True)\n",
    "mu3 = x3.mean(dim=-1, keepdim=True)\n",
    "var3 = ((x3 - mu3) ** 2).mean(dim=-1, keepdim=True)\n",
    "std3 = torch.sqrt(var3 + ln3.eps)\n",
    "xhat3 = (x3 - mu3) / std3\n",
    "y3_ref = xhat3 * gamma3 + beta3\n",
    "loss3_ref = (y3_ref**2).mean()\n",
    "dx3_auto, dgamma3_auto, dbeta3_auto = torch.autograd.grad(loss3_ref, (x3, gamma3, beta3))\n",
    "\n",
    "print(\"[3D] max |dx diff|   =\", (dx3_manual - dx3_auto).abs().max().item())\n",
    "print(\"[3D] max |dgamma diff| =\", (ln3.dgamma - dgamma3_auto).abs().max().item())\n",
    "print(\"[3D] max |dbeta diff|  =\", (ln3.dbeta  - dbeta3_auto ).abs().max().item())\n",
    "\n",
    "# ------------ Quick nn.LayerNorm demo ------------\n",
    "hidden = torch.randn(N, T, D)\n",
    "ln_pt = nn.LayerNorm(D)\n",
    "out = ln_pt(hidden)\n",
    "print(\"nn.LayerNorm out shape:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c03e6-d5a7-443b-afd9-56710ed838ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-dev)",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
