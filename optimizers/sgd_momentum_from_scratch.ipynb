{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc19aee-61d8-4657-a6f5-dffefd7cf662",
   "metadata": {},
   "source": [
    "# SGD with Momentum (From Scratch)\n",
    "\n",
    "In this notebook, we implement **Stochastic Gradient Descent (SGD) with Momentum** from scratch in PyTorch style.  \n",
    "We also compare it with vanilla SGD to see how momentum accelerates learning and reduces oscillations.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48fb1d-862e-486d-8bca-0709dab13311",
   "metadata": {},
   "source": [
    "## ðŸ”¹ SGD with Momentum â€” Definition & Formula\n",
    "\n",
    "- **Vanilla SGD update rule:**\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta g_t\n",
    "$$\n",
    "\n",
    "- **SGD + Momentum update rule:**\n",
    "$$\n",
    "v_t = \\mu v_{t-1} - \\eta g_t\n",
    "$$\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t + v_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $g_t$: gradient at step $t$  \n",
    "- $\\eta$: learning rate  \n",
    "- $\\mu$: momentum coefficient (0â€“1), e.g. 0.9  \n",
    "- $v_t$: velocity (smoothed direction of past gradients)  \n",
    "\n",
    "ðŸ‘‰ **Intuition:** Momentum builds velocity in consistent gradient directions,  \n",
    "so training is faster and smoother, especially in ravines or noisy gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901e799d-03ba-45ef-b8a5-f56c0ae19fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4fce6-3079-4fb2-82bf-363e42681781",
   "metadata": {},
   "source": [
    "## Manual Implementation\n",
    "\n",
    "We first implement the **update step manually** using velocity buffers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3459f4d9-2ef9-4dea-989b-bf822d025669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_velocity(params):\n",
    "    return [torch.zeros_like(p) for p in params]\n",
    "\n",
    "@torch.no_grad()\n",
    "def sgd_momentum_step(params, grads, velocity, lr=0.1, mu=0.9):\n",
    "    for p, g, v in zip(params, grads, velocity):\n",
    "        v.mul_(mu).add_(g, alpha=-lr)   # update velocity\n",
    "        p.add_(v)                       # update parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f56d6c-e7dd-482b-a029-cc1e664237cb",
   "metadata": {},
   "source": [
    "## SGD with Momentum â€” Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5228258-3299-4e44-9105-b26a9539bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDWithMomentum:\n",
    "    def __init__(self, params, lr=0.1, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.mu = momentum\n",
    "        self.velocity = [torch.zeros_like(p) for p in self.params]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for p, v in zip(self.params, self.velocity):\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            v.mul_(self.mu).add_(p.grad, alpha=-self.lr)\n",
    "            p.add_(v)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004a380-5cc4-4323-a928-5b395e9d4b72",
   "metadata": {},
   "source": [
    "## Testing the Optimizer\n",
    "\n",
    "We apply our SGD with Momentum optimizer to a simple linear regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d358f3-5eb8-4f60-9bb3-cb578232b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 11.7060\n",
      "Epoch 2, Loss = 0.1488\n",
      "Epoch 3, Loss = 11.3892\n",
      "Epoch 4, Loss = 5.4412\n",
      "Epoch 5, Loss = 1.4292\n",
      "Epoch 6, Loss = 9.2542\n",
      "Epoch 7, Loss = 1.7752\n",
      "Epoch 8, Loss = 2.8406\n",
      "Epoch 9, Loss = 6.4027\n",
      "Epoch 10, Loss = 0.2354\n",
      "Epoch 11, Loss = 3.5880\n",
      "Epoch 12, Loss = 3.7387\n",
      "Epoch 13, Loss = 0.0309\n",
      "Epoch 14, Loss = 3.5315\n",
      "Epoch 15, Loss = 1.7629\n",
      "Epoch 16, Loss = 0.4119\n",
      "Epoch 17, Loss = 2.8978\n",
      "Epoch 18, Loss = 0.5914\n",
      "Epoch 19, Loss = 0.8551\n",
      "Epoch 20, Loss = 2.0245\n"
     ]
    }
   ],
   "source": [
    "# Dummy dataset\n",
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "y = torch.tensor([[2.0], [4.0], [6.0]])  # y = 2x\n",
    "\n",
    "# Simple model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = SGDWithMomentum(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97c367-7fb4-4fde-89e8-23951717f8e2",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Momentum accelerates SGD in consistent directions and reduces oscillation.  \n",
    "- Update rule introduces a **velocity term** that smooths gradients.  \n",
    "- Widely used in training deep networks before Adam became standard.  \n",
    "- Forms the foundation of more advanced optimizers like **Nesterov** and **Adam**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76499d77-9e56-4774-9e70-b42a903d5123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-dev)",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
